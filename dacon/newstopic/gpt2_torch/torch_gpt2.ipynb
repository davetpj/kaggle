{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"torch_gpt2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WZHM2_E7Aeap"},"source":["# GPT2"],"id":"WZHM2_E7Aeap"},{"cell_type":"markdown","metadata":{"id":"p5r3KZ0V3Oa-"},"source":["## Drive mount"],"id":"p5r3KZ0V3Oa-"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NTub6emlinn4","executionInfo":{"status":"ok","timestamp":1630568293496,"user_tz":-540,"elapsed":899,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"1dfbfe88-17ff-4f2d-8a5a-bb7ef619932e"},"source":["!nvidia-smi"],"id":"NTub6emlinn4","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Sep  2 07:38:12 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbs_u4bXTVez","executionInfo":{"status":"ok","timestamp":1630568295004,"user_tz":-540,"elapsed":792,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"5c1bfb2c-7b7f-4cde-a169-70b82e5a32dd"},"source":["import requests\n","\n","API_URL = \"https://api-inference.huggingface.co/models/skt/ko-gpt-trinity-1.2B-v0.5\"\n","headers = {\"Authorization\": \"Bearer api_AHoiQCKsupBdcobjKBKGVTOoZXyaShLKPZ\"}\n","\n","def query(payload):\n","\tresponse = requests.post(API_URL, headers=headers, json=payload)\n","\treturn response.json()\n","\n","output = query(\"머리아프다 \")\n","output"],"id":"fbs_u4bXTVez","execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'error': 'Model skt/ko-gpt-trinity-1.2B-v0.5 is currently loading',\n"," 'estimated_time': 187.02035844}"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d4eafeb","executionInfo":{"status":"ok","timestamp":1630568346868,"user_tz":-540,"elapsed":41982,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"154a7733-f3e8-4451-e362-da5b4604fb74"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"0d4eafeb","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"W9M7I1rq8az_"},"source":["## Install Transformers"],"id":"W9M7I1rq8az_"},{"cell_type":"code","metadata":{"id":"1mHPLkMhvVMh"},"source":["#\"https://arxiv.org/abs/1901.11196\" data augmentation"],"id":"1mHPLkMhvVMh","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d7-ZQ9Uo440g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630568352957,"user_tz":-540,"elapsed":6097,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"24967162-0f3b-4dd5-fe29-fae8914cd799"},"source":["!pip install transformers"],"id":"d7-ZQ9Uo440g","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 62.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 56.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 49.5 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"-2rLLY0Z8ewI"},"source":["## Import modules"],"id":"-2rLLY0Z8ewI"},{"cell_type":"code","metadata":{"id":"O_OGEiNe4zGB","executionInfo":{"status":"ok","timestamp":1630568596847,"user_tz":-540,"elapsed":491,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["import os\n","import re\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","import warnings\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","\n","from transformers import AutoTokenizer, AutoModelWithLMHead, GPT2ForSequenceClassification, PreTrainedTokenizerFast\n","warnings.filterwarnings('ignore')"],"id":"O_OGEiNe4zGB","execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Rs4hmQ3mYzr","executionInfo":{"status":"ok","timestamp":1630568596848,"user_tz":-540,"elapsed":10,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"b48c6218-8974-4478-ba63-7e5ea1268ad7"},"source":["print(torch.__version__)"],"id":"9Rs4hmQ3mYzr","execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["1.9.0+cu102\n"]}]},{"cell_type":"code","metadata":{"id":"AuWc-cyil9qm","executionInfo":{"status":"ok","timestamp":1630568597224,"user_tz":-540,"elapsed":2,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = '0'"],"id":"AuWc-cyil9qm","execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aaR3V1GN5iM3"},"source":["## Import Data"],"id":"aaR3V1GN5iM3"},{"cell_type":"code","metadata":{"id":"87_pkZtA1sVs","executionInfo":{"status":"ok","timestamp":1630568599737,"user_tz":-540,"elapsed":709,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["PATH = '/content/drive/MyDrive/gh/kaggle/dacon/newstopic'\n","train      = pd.read_csv(PATH + '/DATA/train_clean_4bert.csv')\n","test       = pd.read_csv(PATH + '/DATA/test_clean_4bert.csv')\n","submission = pd.read_csv(PATH + '/DATA/sample_submission.csv')\n","submission_1 = pd.read_csv(PATH + '/DATA/sample_submission.csv')\n","topic_dict = pd.read_csv(PATH + '/DATA/topic_dict.csv')"],"id":"87_pkZtA1sVs","execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_WUGssjmxAU","executionInfo":{"status":"ok","timestamp":1630568600729,"user_tz":-540,"elapsed":24,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"09cc0038-6e09-4ae8-af68-0a1dee50e415"},"source":["train.dtypes"],"id":"9_WUGssjmxAU","execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Unnamed: 0       int64\n","index            int64\n","title           object\n","topic_idx        int64\n","ko_to_en        object\n","en_to_ko        object\n","c_title         object\n","c_title_enko    object\n","dtype: object"]},"metadata":{},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"aJrafMvP5eKg"},"source":["## Tokenizer"],"id":"aJrafMvP5eKg"},{"cell_type":"code","metadata":{"id":"-5poEuXF364z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630568618804,"user_tz":-540,"elapsed":15790,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"849e7604-b1d0-402c-ff55-5279684c8b6d"},"source":["#https://huggingface.co/skt/ko-gpt-trinity-1.2B-v0.5\n","#tokenizer = AutoTokenizer.from_pretrained(\"skt/kogpt2-base-v2\")\n","#tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")\n","#tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")\n","\n","#model = GPT2ForSequenceClassification.from_pretrained(\"skt/kogpt2-base-v2\")\n","#model = GPT2ForSequenceClassification.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")\n","\n","model = AutoModelWithLMHead.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")\n","#model.score = torch.nn.Linear(768, 7)\n","model.score = torch.nn.Linear(1920, 7)\n","\n","model.cuda()"],"id":"-5poEuXF364z","execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 1920)\n","    (wpe): Embedding(1024, 1920)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (12): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (13): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (14): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (15): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (16): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (17): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (18): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (19): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (20): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (21): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (22): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (23): GPT2Block(\n","        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=1920, out_features=51200, bias=False)\n","  (score): Linear(in_features=1920, out_features=7, bias=True)\n",")"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"NO_uWfb05VMo","executionInfo":{"status":"ok","timestamp":1630568618804,"user_tz":-540,"elapsed":8,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["class TrainDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_seq_len=40):\n","        self.data = data\n","        self.max_seq_len = max_seq_len\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        record = self.data.iloc[index]\n","        document, label = str(record['c_title']), int(record['topic_idx'])\n","        tokens = self.tokenizer.tokenize(document)\n","        encoder_input_id = self.tokenizer.convert_tokens_to_ids(tokens)\n","        attention_mask = [1] * len(encoder_input_id)\n","        if len(encoder_input_id) < self.max_seq_len:\n","            while len(encoder_input_id) < self.max_seq_len:\n","                encoder_input_id += [tokenizer.convert_tokens_to_ids('<pad>')]\n","                attention_mask += [0]\n","        else:\n","            encoder_input_id = encoder_input_id[:self.max_seq_len - 1] + [\n","                self.tokenizer.eos_token_id]\n","            attention_mask = attention_mask[:self.max_seq_len]\n","        return {'input_ids': np.array(encoder_input_id, dtype=np.int_),\n","                'attention_mask': np.array(attention_mask, dtype=np.float),\n","                'labels': np.array(label, dtype=np.int_)}\n","    \n","class TestDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_seq_len=40):\n","        self.data = data\n","        self.max_seq_len = max_seq_len\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        record = self.data.iloc[index]\n","        document = str(record['c_title'])\n","        tokens = self.tokenizer.tokenize(document)\n","        encoder_input_id = self.tokenizer.convert_tokens_to_ids(tokens)\n","        attention_mask = [1] * len(encoder_input_id)\n","        if len(encoder_input_id) < self.max_seq_len:\n","            while len(encoder_input_id) < self.max_seq_len:\n","                encoder_input_id += [tokenizer.convert_tokens_to_ids('<pad>')]\n","                attention_mask += [0]\n","        else:\n","            encoder_input_id = encoder_input_id[:self.max_seq_len - 1] + [\n","                self.tokenizer.eos_token_id]\n","            attention_mask = attention_mask[:self.max_seq_len]\n","        return {'input_ids': np.array(encoder_input_id, dtype=np.int_),\n","                'attention_mask': np.array(attention_mask, dtype=np.float)}"],"id":"NO_uWfb05VMo","execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"4m0mE51A5soP","executionInfo":{"status":"ok","timestamp":1630568618805,"user_tz":-540,"elapsed":8,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["# train parameters\n","epochs = 10\n","#batch_size = 32\n","\n","my_learning_rate = 3E-6 # default is 5E-5\n","my_adam_epsilon = 1E-8 # default is 1E-8\n","my_number_of_epochs = 7\n","my_warmup = 3\n","my_mini_batch_size = 16\n","\n","batch_size = my_mini_batch_size"],"id":"4m0mE51A5soP","execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"QMpR1bpc5vS1","executionInfo":{"status":"ok","timestamp":1630568618805,"user_tz":-540,"elapsed":7,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["# train loader\n","# train_ds = TrainDataset(train, tokenizer)\n","# loader = DataLoader(train_ds, batch_size=batch_size, num_workers=0, shuffle=True)\n","\n","train_ds = TrainDataset(train, tokenizer)\n","loader = DataLoader(train_ds, batch_size=batch_size, num_workers=0, shuffle=True)\n","total_steps = len(loader) * epochs"],"id":"QMpR1bpc5vS1","execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJOpAm5kgEkX","executionInfo":{"status":"ok","timestamp":1630568618806,"user_tz":-540,"elapsed":8,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["from transformers import get_linear_schedule_with_warmup"],"id":"DJOpAm5kgEkX","execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"nA5pspav5vi2","executionInfo":{"status":"ok","timestamp":1630568627901,"user_tz":-540,"elapsed":285,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["# # optimizer\n","# optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n","# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 5, )\n","# loss_fn = torch.nn.CrossEntropyLoss()\n","\n","\n","optimizer = torch.optim.AdamW(model.parameters(),\n","                  lr = my_learning_rate, #args.learning_rate\n","                  eps = my_adam_epsilon  #args.adam_epsilon\n","                )\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = my_warmup, \n","                                            num_training_steps = total_steps)\n","loss_fn = torch.nn.CrossEntropyLoss()"],"id":"nA5pspav5vi2","execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNQsX864f4MM","executionInfo":{"status":"ok","timestamp":1630568628237,"user_tz":-540,"elapsed":6,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["import time\n","import datetime\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"id":"GNQsX864f4MM","execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"jdua5C_95vvk","colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"status":"error","timestamp":1630568629236,"user_tz":-540,"elapsed":298,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"30576964-6a63-4774-cee3-44ce111b412b"},"source":["model.train()\n","for e in range(epochs):\n","    total_loss = 0\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(e + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","    for step, batch in enumerate(loader):\n","        if step % 100 == 0 and not step == 0:\n","        # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(loader), elapsed))\n","\n","        optimizer.zero_grad()\n","        ids, atts, labels = batch['input_ids'], batch['attention_mask'], batch['labels']\n","        ids = torch.tensor(ids).long().cuda()\n","        atts = torch.tensor(atts).long().cuda()\n","        labels = torch.tensor(labels).long().cuda()\n","        pred = model(ids, attention_mask=atts)\n","        loss = loss_fn(pred[0], labels)\n","        \n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n","        optimizer.step()\n","        total_loss += loss.item()\n","    avg_train_loss = total_loss / len(loader) \n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))        \n","    scheduler.step()\n","    print(e, total_loss)\n","print(\"\")\n","print(\"Training complete!\")"],"id":"jdua5C_95vvk","execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Epoch 1 / 10 ========\n","Training...\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-2102838aa51c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0matts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         )\n\u001b[1;32m    964\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    799\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m                 )\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mfeed_forward_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;31m# residual connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeed_forward_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/activations.py\u001b[0m in \u001b[0;36mgelu_new\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mthe\u001b[0m \u001b[0mGaussian\u001b[0m \u001b[0mError\u001b[0m \u001b[0mLinear\u001b[0m \u001b[0mUnits\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1606.08415\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \"\"\"\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.044715\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.90 GiB total capacity; 14.52 GiB already allocated; 33.75 MiB free; 14.97 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"Nlpr6LUE5v9R"},"source":["# test loader\n","test_ds = TestDataset(test, tokenizer)\n","test_loader = DataLoader(test_ds, 8)"],"id":"Nlpr6LUE5v9R","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a61yoriZ7yfv","executionInfo":{"status":"ok","timestamp":1630492742268,"user_tz":-540,"elapsed":19832,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"8f06dc4c-5bbc-494d-87b4-d65ccff7cae2"},"source":["preds = []\n","model.eval()\n","\n","for b in tqdm(test_loader):\n","    ids, atts = b['input_ids'], b['attention_mask']\n","    ids = torch.tensor(ids).long().cuda()\n","    atts = torch.tensor(atts).long().cuda()\n","    pred = model(ids, attention_mask=atts)\n","    preds += list(np.argmax(pred[0].detach().cpu().numpy(), 1))\n","#     break"],"id":"a61yoriZ7yfv","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1142/1142 [00:19<00:00, 57.38it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"id":"Ka-qoWpG74M2","executionInfo":{"status":"ok","timestamp":1630492745403,"user_tz":-540,"elapsed":261,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"fc24e712-f997-4048-9ef7-8e5cdaa6e562"},"source":["submission['topic_idx'] = preds\n","submission.head(20)"],"id":"Ka-qoWpG74M2","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>topic_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>45654</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>45655</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>45656</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>45657</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>45658</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>45659</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>45660</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>45661</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>45662</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>45663</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>45664</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>45665</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>45666</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>45667</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>45668</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>45669</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>45670</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>45671</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>45672</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>45673</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    index  topic_idx\n","0   45654          0\n","1   45655          3\n","2   45656          2\n","3   45657          0\n","4   45658          3\n","5   45659          0\n","6   45660          5\n","7   45661          3\n","8   45662          4\n","9   45663          1\n","10  45664          4\n","11  45665          6\n","12  45666          4\n","13  45667          5\n","14  45668          6\n","15  45669          1\n","16  45670          6\n","17  45671          2\n","18  45672          4\n","19  45673          4"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"NVzn_N308ATK"},"source":["submission.to_csv(PATH + '/gpt2_test.csv', index = False)"],"id":"NVzn_N308ATK","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrUHDSqJ5wKc","executionInfo":{"status":"ok","timestamp":1630492531125,"user_tz":-540,"elapsed":20297,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"52f55ef8-91f9-4c4d-caa2-958593fab21f"},"source":["# preds = []\n","# model.eval()\n","# #preds_1 = []\n","# true = []\n","# for b in tqdm(test_loader):\n","#     ids, atts = b['input_ids'], b['attention_mask']\n","#     ids = torch.tensor(ids).long().cuda()\n","#     atts = torch.tensor(atts).long().cuda()\n","#     pred = model(ids, attention_mask=atts)\n","#     logits1 = pred[0]\n","#     logits1 = logits1.detach().cpu().numpy()\n","#     preds_1.append(logits1)\n","#     preds += list(np.argmax(pred[0].detach().cpu().numpy(), 1))\n","# #     break\n","# #flat_predictions_1 = [item for sublist in preds_1 for item in sublist]"],"id":"jrUHDSqJ5wKc","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1142/1142 [00:19<00:00, 57.29it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"1OleFFe3AB9u"},"source":["## Submission"],"id":"1OleFFe3AB9u"},{"cell_type":"code","metadata":{"id":"x32sOW4Pgiqe"},"source":["# # Combine the predictions for each batch into a single list of 0s and 1s.\n","# flat_predictions = [item for sublist in preds for item in sublist]\n","# flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","# valid_flat_predictions = np.argmax(valid_flat_predictions, axis=1).flatten()\n","# #"],"id":"x32sOW4Pgiqe","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YcrokuRg58zr"},"source":["# submission['topic_idx'] = preds\n","# submission.head(20)\n"],"id":"YcrokuRg58zr","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EwJTTURc6tY9"},"source":["# submission.to_csv(PATH + '/koGPT2/maxlen40_gpt2_torch.csv', index = False)"],"id":"EwJTTURc6tY9","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rthcidzlg58I"},"source":["# # Combine the predictions for each batch into a single list of 0s and 1s.\n","# flat_predictions = [item for sublist in preds for item in sublist]\n","# flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","# valid_flat_predictions = np.argmax(valid_flat_predictions, axis=1).flatten()\n","# #"],"id":"Rthcidzlg58I","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnc68TI2hVjP"},"source":["# import torch.nn.functional as F\n","# z = torch.FloatTensor(flat_predictions_1)\n","\n","# probs_1 = F.softmax(z, dim=1)\n","# probs_1 = (probs_1).tolist()\n","\n","# i, j, k=  [], [], []\n","# m, n, o = [], [], []\n","# l = []\n","# for row in probs_1:\n","#   i.append(row[0])\n","#   j.append(row[1])\n","#   k.append(row[2])\n","#   l.append(row[3])\n","#   m.append(row[4])\n","#   n.append(row[5])\n","#   o.append(row[6])\n","\n","\n","# submission_1['0'] = i\n","# submission_1['1'] = j\n","# submission_1['2'] = k\n","# submission_1['3'] = l\n","# submission_1['4'] = m\n","# submission_1['5'] = n\n","# submission_1['6'] = o\n","# submission_1.topic_idx = preds\n","\n","# submission_1.to_csv(PATH + '/koGPT2/koGPT2_proba_.csv',index = False)"],"id":"dnc68TI2hVjP","execution_count":null,"outputs":[]}]}
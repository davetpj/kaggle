{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"koELECTRA.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1fP5njcBt7lYvv9MPEG55AXCgx9X8QD1y","authorship_tag":"ABX9TyMOOoHUKIaIdid+LwTSP3BL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"21cb1eea2b97483f9c65028b8fdccbc4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_088990b8ad0c4345bb2f70c84a0da159","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6c75037c752a467fa4f3ea12d04e4b3d","IPY_MODEL_b9d3afb5ec2747d38aa60c2c472d7f66"]}},"088990b8ad0c4345bb2f70c84a0da159":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c75037c752a467fa4f3ea12d04e4b3d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b776a54ee855455aa0b95f491bdb8c87","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":255190,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":255190,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_22f92e4935b94d06bd1ff817900edc72"}},"b9d3afb5ec2747d38aa60c2c472d7f66":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b0db6493306546f8b8fc1df5bd7ea082","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 255k/255k [00:01&lt;00:00, 202kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bb0238d22a7f439885e7db7a617571cd"}},"b776a54ee855455aa0b95f491bdb8c87":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"22f92e4935b94d06bd1ff817900edc72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0db6493306546f8b8fc1df5bd7ea082":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bb0238d22a7f439885e7db7a617571cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9483565506544e3d8224d2847a4c5fbc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8ec7c728bc314d188261b15719f02ec4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_33218593d3194af581c6c9ea666551a7","IPY_MODEL_f4ffbc01e8874e9da7b4d725781bd233"]}},"8ec7c728bc314d188261b15719f02ec4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"33218593d3194af581c6c9ea666551a7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6e50381d0362471c8264307998408e3e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":65,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":65,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_605071ee8ec74f22a3d322184244c4ba"}},"f4ffbc01e8874e9da7b4d725781bd233":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1a7aacb25641423d9cc7d5d51a93cf57","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 65.0/65.0 [00:00&lt;00:00, 70.2B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3adf8ab0e5b44360bc2e88dffe0d2206"}},"6e50381d0362471c8264307998408e3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"605071ee8ec74f22a3d322184244c4ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a7aacb25641423d9cc7d5d51a93cf57":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3adf8ab0e5b44360bc2e88dffe0d2206":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c6950c28e5949e38ae09ce90e231f34":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_db75d246c67147f98ab3761e16cd200e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f30f7649ec81432f9fc7a3a6d3b079dd","IPY_MODEL_a1f0791655c0488583dc906a00a33afc"]}},"db75d246c67147f98ab3761e16cd200e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f30f7649ec81432f9fc7a3a6d3b079dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f8f2ed5693764230bac2f17a034fe3bd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":487,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":487,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b95d50853a84dc4861c0c3d78a3cff3"}},"a1f0791655c0488583dc906a00a33afc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e4b81aa0d9084a4fa14997b031ca9d74","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 487/487 [00:00&lt;00:00, 8.03kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_960b5ca5a4a14eb39264015682e8dbee"}},"f8f2ed5693764230bac2f17a034fe3bd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1b95d50853a84dc4861c0c3d78a3cff3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e4b81aa0d9084a4fa14997b031ca9d74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"960b5ca5a4a14eb39264015682e8dbee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"913a0c17a4e543bd82149bd8250d099e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b148ee830f8649499713b463484471fc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c1a3182878714cb694ce287ae7057dad","IPY_MODEL_0461a3252e3d4da4bbdd81508900fe07"]}},"b148ee830f8649499713b463484471fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1a3182878714cb694ce287ae7057dad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e3d7df3dd8914dcd939b4775dc37a915","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":443135628,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":443135628,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b1f49d4369ee4a22aff4f20c2cf1ed02"}},"0461a3252e3d4da4bbdd81508900fe07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b95f339362584520b5349c44939c7236","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 443M/443M [00:24&lt;00:00, 17.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1ae5e04fdbaf4f6b84444676ef6e01cf"}},"e3d7df3dd8914dcd939b4775dc37a915":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b1f49d4369ee4a22aff4f20c2cf1ed02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b95f339362584520b5349c44939c7236":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1ae5e04fdbaf4f6b84444676ef6e01cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r8xGzttd5222","executionInfo":{"status":"ok","timestamp":1627946664032,"user_tz":-540,"elapsed":439,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"b03ba186-03b8-49d2-b0a2-27b546b9326f"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mon Aug  2 23:24:23 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"COYPdAa46QeY"},"source":["!pip install torch_optimizer\n","!pip install transformers\n","!pip install pytorchtools"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pzv7mxk-6bh_"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","import json\n","import matplotlib.pyplot as plt\n","# from adamp import AdamP\n","import seaborn as sns\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","\n","\n","import torch\n","import torch_optimizer as optim\n","#from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","#import pytorch_lightning as pl\n","\n","from transformers import ElectraTokenizer, ElectraForSequenceClassification,AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","\n","# 그래프를 출력창에서 바로 볼 수 있게함\n","%matplotlib inline \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGmQWp5M6l0w"},"source":["my_learning_rate = 3E-6 # default is 5E-5\n","my_adam_epsilon = 1E-8 # default is 1E-8\n","my_number_of_epochs = 12\n","my_warmup = 3\n","my_mini_batch_size = 128\n","max_len = 32"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bq2Ctxta6hP_","executionInfo":{"status":"ok","timestamp":1627950603315,"user_tz":-540,"elapsed":255,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"ec3ed259-6ba7-4cf7-b78f-8d4952e03856"},"source":["\"\"\"\n","GPU를 사용 가능한지 여부를 True, False로 나타냄\n","torch.cuda.is_available()\n"," \n","GPU 이름\n","torch.cuda.get_device_name(0)\n","\"\"\"\n","if torch.cuda.is_available():  \n","    device = torch.device(\"cuda\")\n","    print('I will use the GPU:', torch.cuda.get_device_name(0))\n","    \n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["I will use the GPU: Tesla P100-PCIE-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"naPEdi_r6oZe"},"source":["#################\n","\n","#################\n","## Import DATA, submission file\n","PATH = '/content/drive/MyDrive/gh/dacon_newstopic'\n","train      = pd.read_csv(PATH + '/DATA/train_clean_data.csv')\n","test       = pd.read_csv(PATH + '/DATA/test_clean_data.csv')\n","submission = pd.read_csv(PATH + '/DATA/sample_submission.csv')\n","topic_dict = pd.read_csv(PATH + '/DATA/topic_dict.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFML90zi67PE"},"source":["# train data와 label 데이터 설정\n","texts = train['c_title']\n","labels = train['topic_idx']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kp2d40tT7xEa"},"source":["for n in range(200, 1000):\n","    print(texts[n], \"(LABEL:\", labels[n], \")\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["21cb1eea2b97483f9c65028b8fdccbc4","088990b8ad0c4345bb2f70c84a0da159","6c75037c752a467fa4f3ea12d04e4b3d","b9d3afb5ec2747d38aa60c2c472d7f66","b776a54ee855455aa0b95f491bdb8c87","22f92e4935b94d06bd1ff817900edc72","b0db6493306546f8b8fc1df5bd7ea082","bb0238d22a7f439885e7db7a617571cd","9483565506544e3d8224d2847a4c5fbc","8ec7c728bc314d188261b15719f02ec4","33218593d3194af581c6c9ea666551a7","f4ffbc01e8874e9da7b4d725781bd233","6e50381d0362471c8264307998408e3e","605071ee8ec74f22a3d322184244c4ba","1a7aacb25641423d9cc7d5d51a93cf57","3adf8ab0e5b44360bc2e88dffe0d2206","5c6950c28e5949e38ae09ce90e231f34","db75d246c67147f98ab3761e16cd200e","f30f7649ec81432f9fc7a3a6d3b079dd","a1f0791655c0488583dc906a00a33afc","f8f2ed5693764230bac2f17a034fe3bd","1b95d50853a84dc4861c0c3d78a3cff3","e4b81aa0d9084a4fa14997b031ca9d74","960b5ca5a4a14eb39264015682e8dbee","913a0c17a4e543bd82149bd8250d099e","b148ee830f8649499713b463484471fc","c1a3182878714cb694ce287ae7057dad","0461a3252e3d4da4bbdd81508900fe07","e3d7df3dd8914dcd939b4775dc37a915","b1f49d4369ee4a22aff4f20c2cf1ed02","b95f339362584520b5349c44939c7236","1ae5e04fdbaf4f6b84444676ef6e01cf"]},"id":"GSGcG3_R7yMV","executionInfo":{"status":"ok","timestamp":1627950645072,"user_tz":-540,"elapsed":30674,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"dde2dd17-ecfa-4199-e9c2-a11ac9299834"},"source":["\"\"\"\n","Electra is selected here, its pretraining method is more advanced than BERT's MLM. \n","AdamW is Adam with weight decay correction.\n","\"\"\"\n","tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v2-discriminator\") \n","model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v2-discriminator\",num_labels=7) #let's try out electra's base discriminator\n","\n","# tensor를 만든후 GPU에 할당하고 싶을 때  \n","\n","# a = torch.tensor([1., 2.], device=cuda)\n"," \n","# b = torch.tensor([1., 2.]).cuda()\n","\n","# b2 = torch.tensor([1., 2.]).to(device=cuda)\n","\n","\n","# 아니면 Model을 선언후 모든 parameter를 \n","# model.cuda()를 통해 GPU에 로딩할 수 있음\n","\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21cb1eea2b97483f9c65028b8fdccbc4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=255190.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9483565506544e3d8224d2847a4c5fbc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=65.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5c6950c28e5949e38ae09ce90e231f34","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=487.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"913a0c17a4e543bd82149bd8250d099e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443135628.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at monologg/koelectra-base-v2-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v2-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(32200, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mcFaQub378Cp","executionInfo":{"status":"ok","timestamp":1627950688512,"user_tz":-540,"elapsed":8301,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"5fe18a7e-97f9-49f1-9995-0db533fc0137"},"source":["indices=tokenizer.batch_encode_plus(texts,\n","                                    max_length=max_len,\n","                                    add_special_tokens=True, \n","                                    return_attention_mask=True,\n","                                    pad_to_max_length=True,\n","                                    truncation=True)\n","\n","# bert와 달리(bert는 3개) input data가 2개임\n","\n","input_ids=indices[\"input_ids\"]\n","attention_masks=indices[\"attention_mask\"]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"EuH-iE_N8Fz5"},"source":["\n","\"\"\"\n","input_ids=indices[\"input_ids\"]\n","attention_masks=indices[\"attention_mask\"]\n","\"\"\"\n","train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","                                                            random_state=42, test_size=0.2)\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n","                                             random_state=42, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"75V4xDVu8JoB"},"source":["\n","# 만들어진 모든 data를 torch.tensor을 통해 tensor로 변환\n","# torch.long 은  np.int64 와 같음\n","\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels, dtype=torch.long)\n","validation_labels = torch.tensor(validation_labels.tolist(), dtype=torch.long) # list 변환 해줘야함\n","train_masks = torch.tensor(train_masks, dtype=torch.long)\n","validation_masks = torch.tensor(validation_masks, dtype=torch.long)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0AUq7nnz8J9I"},"source":["\n","# pytorch는  torch.utils.data.Dataset으로 Custom Dataset을 만들고, \n","# torch.utils.data.DataLoader로 데이터를 불러옴 \n","\n","batch_size = my_mini_batch_size\n","\n","\"\"\"Create the DataLoader for our training set.\"\"\"\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","#### DataLoader ###\n","# DataLoader를 통해 반복분을 돌리면  (batch_size, *(data.shape))의 형태의 Tensor로 데이터가 반환\n","# sampler : index를 컨트롤하는 방법, 즉 데이터의 index를 원하는 방식대로 조정\n","# sampler option \n","\n","# SequentialSampler : 항상 같은 순서\n","# RandomSampler : 랜덤, replacemetn 여부 선택 가능, 개수 선택 가능\n","\n","# SubsetRandomSampler : 랜덤 리스트, 위와 두 조건 불가능\n","# WeigthRandomSampler : 가중치에 따른 확률\n","# BatchSampler : batch단위로 sampling 가능\n","# DistributedSampler : 분산처리 (torch.nn.parallel.DistributedDataParallel과 함께 사용)\n","\n","\n","\"\"\" Create the DataLoader for our validation set.\"\"\"\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data) \n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91KTacUb8Luv"},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = my_learning_rate, #args.learning_rate\n","                  eps = my_adam_epsilon  #args.adam_epsilon\n","\n","                )\n","\n","\"\"\"\n","my_learning_rate = 3E-6 # default is 5E-5\n","my_adam_epsilon = 1E-8 # default is 1E-6\n","my_number_of_epochs = 7\n","my_warmup = 3\n","my_mini_batch_size = 128\n","\n","\"\"\"\n","\n","\n","# epoch 수 설정\n","epochs = my_number_of_epochs\n","\n","# Total number of training steps is number of batches * number of epochs.\n","# batchs * epoch 수 만큼의 훈련을 함\n","total_steps = len(train_dataloader) * epochs\n","\n","\"\"\" warmup\n","내가 정한 learning rate가 0.01이라고 한다면 처음 10 step 동안은 \n","0.001, 0.002, 0.003 ~ 0.01까지 선형적으로 조금씩만 증가하는 learning rate을 사용\n","\n","이러한 방식은 warmup step을 따로 정해줘야 함\n","\"\"\"\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer,\n","                                            num_warmup_steps = my_warmup, \n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rdfeBjLQ8R7d"},"source":["\n","#about evalution mert - here we use accuracy, which is good enough because the data is\n","#is binary classified and distribution is pretty even between positive and negative\n","#however better evaluation should be use later F1 or AUC ROC because emergency are\n","#events rare tweets\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXYOeHhx8Ttl"},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rtzQt468VHm","executionInfo":{"status":"ok","timestamp":1627951973048,"user_tz":-540,"elapsed":1280847,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"89ab7463-ed3b-485a-d6e4-5fa2e1db90da"},"source":["import random\n","\n","# Base on GLUE from huggingface, this is classification problem best suit our problem, here, look at the\n","# example Python code from hungingface gtihub, here is the here training loop\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Store the average loss after each epoch so we can plot them.\n","loss_values = []\n","\n","# For each epoch...\n","\n","for epoch_i in range(0, epochs):\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_loss = 0\n","\n","    model.train()\n","\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 100 batches.\n","        if step % 50 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # `batch` contains three pytorch tensors: [0]: input ids ,[1]: attention masks,[2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Clear any previously calculated gradients.\n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Evaluate the model on this training batch.\n","        outputs = model(b_input_ids, \n","                    token_type_ids=None, \n","                    attention_mask=b_input_mask, \n","                    labels=b_labels)\n","        loss = outputs[0]\n","\n","        # Accumulate the training loss over all of the batches \n","        total_loss += loss.item()\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0. to prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)       \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","   \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n","      \n","print(\"\")\n","print(\"Training complete!\")\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:34.\n","\n","  Average training loss: 1.76\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 2 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:34.\n","\n","  Average training loss: 1.09\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 3 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.71\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 4 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.57\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 5 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.50\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 6 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.47\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 7 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.44\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 8 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.43\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 9 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.42\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 10 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.41\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 11 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.40\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 12 / 12 ========\n","Training...\n","  Batch    50  of    286.    Elapsed: 0:00:19.\n","  Batch   100  of    286.    Elapsed: 0:00:37.\n","  Batch   150  of    286.    Elapsed: 0:00:56.\n","  Batch   200  of    286.    Elapsed: 0:01:15.\n","  Batch   250  of    286.    Elapsed: 0:01:33.\n","\n","  Average training loss: 0.40\n","  Training epoch took: 0:01:47\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCTkU-bl8km5","executionInfo":{"status":"ok","timestamp":1627953145493,"user_tz":-540,"elapsed":8838,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"a2ddf02d-b87e-4909-c9f6-0999a093c1ad"},"source":["# Validation\n","print(\"\")\n","print(\"Running Validation...\")\n","\n","t0 = time.time()\n","model.eval()\n","\n","preds=[]\n","true=[]\n","\n","# Tracking variables \n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# Evaluate data for one epoch\n","for batch in validation_dataloader:\n","    \n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    \n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","    with torch.no_grad():        \n","\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # Get the \"logits\" output by the model. The \"logits\" are the output values prior to applying an activation function like the softmax.\n","    logits = outputs[0]\n","\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","    preds.append(logits)\n","    true.append(label_ids)\n","    # Calculate the accuracy for this batch.\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    \n","    # Accumulate the total accuracy.\n","    eval_accuracy += tmp_eval_accuracy\n","\n","    # Track the number of batches\n","    nb_eval_steps += 1\n","valid_flat_predictions = [item for sublist in preds for item in sublist]\n","# Report the final accuracy for this validation run.\n","print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Running Validation...\n","  Accuracy: 0.87\n","  Validation took: 0:00:09\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XPtHOREoCJo8"},"source":["# Combine the predictions for each batch into a single list of 0s and 1s.\n","flat_predictions = [item for sublist in preds for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n","valid_flat_predictions = np.argmax(valid_flat_predictions, axis=1).flatten()\n","# Combine the correct labels for each batch into a single list.\n","flat_true_labels = [item for sublist in true for item in sublist]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_sCDW1zCPEL","executionInfo":{"status":"ok","timestamp":1627953145496,"user_tz":-540,"elapsed":9,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"e32888d7-6df6-45e4-956c-2307ffc2f9c6"},"source":["from sklearn.metrics import classification_report\n","print(classification_report(flat_predictions,flat_true_labels))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.87      0.79      0.83      1102\n","           1       0.81      0.84      0.82      1183\n","           2       0.73      0.79      0.76      1365\n","           3       0.87      0.87      0.87      1117\n","           4       0.93      0.90      0.92      1541\n","           5       0.97      0.96      0.96      1466\n","           6       0.90      0.91      0.90      1357\n","\n","    accuracy                           0.87      9131\n","   macro avg       0.87      0.87      0.87      9131\n","weighted avg       0.87      0.87      0.87      9131\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLDnShBtCQKS","executionInfo":{"status":"ok","timestamp":1627953147125,"user_tz":-540,"elapsed":1636,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"43632e35-a164-4cd4-80b0-55c0f108ef57"},"source":["text1 = test['c_test']\n","\n","indices1=tokenizer.batch_encode_plus(text1,\n","                                     max_length=32,\n","                                     add_special_tokens=True, \n","                                     return_attention_mask=True,\n","                                     pad_to_max_length=True,\n","                                     truncation=True)\n","input_ids1=indices1[\"input_ids\"]\n","attention_masks1=indices1[\"attention_mask\"]\n","\n","prediction_inputs1= torch.tensor(input_ids1)\n","prediction_masks1 = torch.tensor(attention_masks1)\n","\n","\n","# Set the batch size.  \n","batch_size = my_mini_batch_size\n","\n","# Create the DataLoader.\n","prediction_data1 = TensorDataset(prediction_inputs1, prediction_masks1)\n","prediction_sampler1 = SequentialSampler(prediction_data1)\n","prediction_dataloader1 = DataLoader(prediction_data1, sampler=prediction_sampler1, batch_size=batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iTr34cDACmHz","executionInfo":{"status":"ok","timestamp":1627953155738,"user_tz":-540,"elapsed":8617,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"0eec8f44-0e3d-4b70-c11d-581fbbfa7c5c"},"source":["print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs1)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions = []\n","\n","# Predict \n","for batch in prediction_dataloader1:\n","\n","  # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","    b_input_ids1, b_input_mask1 = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","    with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs1 = model(b_input_ids1, token_type_ids=None, \n","                      attention_mask=b_input_mask1)\n","\n","    logits1 = outputs1[0]\n","\n","  # Move logits and labels to CPU\n","    logits1 = logits1.detach().cpu().numpy()\n","  \n","  \n","  # Store predictions and true labels\n","    predictions.append(logits1)\n","\n","flat_predictions = [item for sublist in predictions for item in sublist]\n","flat_predictions_1 = [item for sublist in predictions for item in sublist]\n","flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicting labels for 9,131 test sentences...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dgocnUWWCynU"},"source":["import torch.nn.functional as F"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QoBIwDi9C3u1","executionInfo":{"status":"ok","timestamp":1627953155741,"user_tz":-540,"elapsed":11,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"83c8f11c-eb4f-45d0-c1ba-70ab29639978"},"source":["z = torch.FloatTensor(flat_predictions_1)\n","probs_1 = F.softmax(z, dim=1)\n","probs_1 = (probs_1).tolist()\n","flat_predictions"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 3, 2, ..., 2, 0, 2])"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"--hqoVjbC_j_"},"source":["i, j, k=  [], [], []\n","m, n, o = [], [], []\n","l = []\n","for row in probs_1:\n","  i.append(row[0])\n","  j.append(row[1])\n","  k.append(row[2])\n","  l.append(row[3])\n","  m.append(row[4])\n","  n.append(row[5])\n","  o.append(row[6])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwZzKfyJDA9_"},"source":["submission_1 = submission\n","submission_1['0'] = i\n","submission_1['1'] = j\n","submission_1['2'] = k\n","submission_1['3'] = l\n","submission_1['4'] = m\n","submission_1['5'] = n\n","submission_1['6'] = o"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2H-dttpaDDC2"},"source":["submission_1.topic_idx = flat_predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"id":"qVxyAm7bDGXp","executionInfo":{"status":"ok","timestamp":1627953171593,"user_tz":-540,"elapsed":16,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"cc3a5360-42be-4a61-b38b-15ba4a24fb9e"},"source":["submission_1[:12]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>topic_idx</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>45654</td>\n","      <td>0</td>\n","      <td>0.799334</td>\n","      <td>0.023457</td>\n","      <td>0.112502</td>\n","      <td>0.043212</td>\n","      <td>0.009871</td>\n","      <td>0.008006</td>\n","      <td>0.003617</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>45655</td>\n","      <td>3</td>\n","      <td>0.005623</td>\n","      <td>0.004369</td>\n","      <td>0.011433</td>\n","      <td>0.968275</td>\n","      <td>0.003912</td>\n","      <td>0.004565</td>\n","      <td>0.001822</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>45656</td>\n","      <td>2</td>\n","      <td>0.116257</td>\n","      <td>0.049765</td>\n","      <td>0.804231</td>\n","      <td>0.008282</td>\n","      <td>0.007168</td>\n","      <td>0.004123</td>\n","      <td>0.010173</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>45657</td>\n","      <td>2</td>\n","      <td>0.022933</td>\n","      <td>0.010146</td>\n","      <td>0.912220</td>\n","      <td>0.029071</td>\n","      <td>0.006535</td>\n","      <td>0.004358</td>\n","      <td>0.014736</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>45658</td>\n","      <td>3</td>\n","      <td>0.005306</td>\n","      <td>0.004042</td>\n","      <td>0.014073</td>\n","      <td>0.966153</td>\n","      <td>0.003800</td>\n","      <td>0.004663</td>\n","      <td>0.001963</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>45659</td>\n","      <td>0</td>\n","      <td>0.837380</td>\n","      <td>0.028925</td>\n","      <td>0.074656</td>\n","      <td>0.043698</td>\n","      <td>0.006368</td>\n","      <td>0.006166</td>\n","      <td>0.002809</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>45660</td>\n","      <td>5</td>\n","      <td>0.003512</td>\n","      <td>0.002115</td>\n","      <td>0.002885</td>\n","      <td>0.002479</td>\n","      <td>0.008621</td>\n","      <td>0.975553</td>\n","      <td>0.004835</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>45661</td>\n","      <td>3</td>\n","      <td>0.006418</td>\n","      <td>0.004316</td>\n","      <td>0.019176</td>\n","      <td>0.959936</td>\n","      <td>0.003636</td>\n","      <td>0.004392</td>\n","      <td>0.002125</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>45662</td>\n","      <td>4</td>\n","      <td>0.003747</td>\n","      <td>0.004506</td>\n","      <td>0.005790</td>\n","      <td>0.003162</td>\n","      <td>0.969520</td>\n","      <td>0.003757</td>\n","      <td>0.009517</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>45663</td>\n","      <td>4</td>\n","      <td>0.013780</td>\n","      <td>0.071222</td>\n","      <td>0.015737</td>\n","      <td>0.007525</td>\n","      <td>0.872717</td>\n","      <td>0.008308</td>\n","      <td>0.010712</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>45664</td>\n","      <td>4</td>\n","      <td>0.004481</td>\n","      <td>0.004463</td>\n","      <td>0.008816</td>\n","      <td>0.004410</td>\n","      <td>0.963685</td>\n","      <td>0.003633</td>\n","      <td>0.010512</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>45665</td>\n","      <td>6</td>\n","      <td>0.003143</td>\n","      <td>0.004214</td>\n","      <td>0.014547</td>\n","      <td>0.003044</td>\n","      <td>0.009030</td>\n","      <td>0.005518</td>\n","      <td>0.960504</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    index  topic_idx         0  ...         4         5         6\n","0   45654          0  0.799334  ...  0.009871  0.008006  0.003617\n","1   45655          3  0.005623  ...  0.003912  0.004565  0.001822\n","2   45656          2  0.116257  ...  0.007168  0.004123  0.010173\n","3   45657          2  0.022933  ...  0.006535  0.004358  0.014736\n","4   45658          3  0.005306  ...  0.003800  0.004663  0.001963\n","5   45659          0  0.837380  ...  0.006368  0.006166  0.002809\n","6   45660          5  0.003512  ...  0.008621  0.975553  0.004835\n","7   45661          3  0.006418  ...  0.003636  0.004392  0.002125\n","8   45662          4  0.003747  ...  0.969520  0.003757  0.009517\n","9   45663          4  0.013780  ...  0.872717  0.008308  0.010712\n","10  45664          4  0.004481  ...  0.963685  0.003633  0.010512\n","11  45665          6  0.003143  ...  0.009030  0.005518  0.960504\n","\n","[12 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"NqbbBGlDDIND","executionInfo":{"status":"ok","timestamp":1627953173059,"user_tz":-540,"elapsed":231,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"ee5d39ce-0f47-4754-9583-7835b7593385"},"source":["# pred = np.argmax(predictions, axis = 1)\n","submission = pd.read_csv(\"/content/drive/MyDrive/gh/dacon_newstopic/DATA/sample_submission.csv\",error_bad_lines=False)\n","submission.topic_idx = flat_predictions\n","submission.sample(3)\n","\n","#submission.to_csv(path, index = False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>topic_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4043</th>\n","      <td>49697</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>3573</th>\n","      <td>49227</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4505</th>\n","      <td>50159</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      index  topic_idx\n","4043  49697          6\n","3573  49227          6\n","4505  50159          3"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"3mZzJ67aDLcY","executionInfo":{"status":"ok","timestamp":1627953174616,"user_tz":-540,"elapsed":295,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"b43135cc-3dce-4086-f07f-fd9635d2accf"},"source":["submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>topic_idx</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>45654</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>45655</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>45656</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>45657</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>45658</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9126</th>\n","      <td>54780</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>9127</th>\n","      <td>54781</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9128</th>\n","      <td>54782</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9129</th>\n","      <td>54783</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9130</th>\n","      <td>54784</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9131 rows × 2 columns</p>\n","</div>"],"text/plain":["      index  topic_idx\n","0     45654          0\n","1     45655          3\n","2     45656          2\n","3     45657          2\n","4     45658          3\n","...     ...        ...\n","9126  54780          3\n","9127  54781          2\n","9128  54782          2\n","9129  54783          0\n","9130  54784          2\n","\n","[9131 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"9pwXluH-eGo1","colab":{"base_uri":"https://localhost:8080/","height":297},"executionInfo":{"status":"ok","timestamp":1627953177747,"user_tz":-540,"elapsed":230,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"944e37aa-f98e-482c-b075-c364c0cdbc5e"},"source":["crosstab = pd.crosstab(validation_labels, valid_flat_predictions, rownames=['real'], colnames=['pred'])\n","crosstab"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>pred</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","    </tr>\n","    <tr>\n","      <th>real</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>866</td>\n","      <td>36</td>\n","      <td>54</td>\n","      <td>14</td>\n","      <td>14</td>\n","      <td>8</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>116</td>\n","      <td>993</td>\n","      <td>74</td>\n","      <td>6</td>\n","      <td>27</td>\n","      <td>9</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>62</td>\n","      <td>115</td>\n","      <td>1082</td>\n","      <td>86</td>\n","      <td>39</td>\n","      <td>13</td>\n","      <td>86</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>32</td>\n","      <td>12</td>\n","      <td>67</td>\n","      <td>977</td>\n","      <td>22</td>\n","      <td>5</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17</td>\n","      <td>16</td>\n","      <td>12</td>\n","      <td>19</td>\n","      <td>1386</td>\n","      <td>19</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>12</td>\n","      <td>8</td>\n","      <td>1406</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>69</td>\n","      <td>3</td>\n","      <td>45</td>\n","      <td>6</td>\n","      <td>1229</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["pred    0    1     2    3     4     5     6\n","real                                       \n","0     866   36    54   14    14     8     3\n","1     116  993    74    6    27     9     5\n","2      62  115  1082   86    39    13    86\n","3      32   12    67  977    22     5     7\n","4      17   16    12   19  1386    19    19\n","5       7    3     7   12     8  1406     8\n","6       2    8    69    3    45     6  1229"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"no0HkBSsDNKh"},"source":["submission.to_csv(\"/content/drive/MyDrive/gh/dacon_newstopic/DATA/koelectra_dh3.csv\",index = False)\n","# submission.to_csv('bert_baseline_1.csv',index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2c0_agVIDuti","executionInfo":{"status":"ok","timestamp":1627746613685,"user_tz":-540,"elapsed":4089,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"fc43713a-1950-4f5c-9255-42338cdfae8e"},"source":["!pip install /content/drive/MyDrive/gh/dacon_newstopic/DATA/dacon_submit_api-0.0.4-py3-none-any.whl"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Processing ./drive/MyDrive/gh/dacon_newstopic/DATA/dacon_submit_api-0.0.4-py3-none-any.whl\n","Installing collected packages: dacon-submit-api\n","Successfully installed dacon-submit-api-0.0.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NTd3AIadIKI_","executionInfo":{"status":"ok","timestamp":1627746628547,"user_tz":-540,"elapsed":5346,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"14472eef-12a4-4fd9-b955-041fbd1aa704"},"source":["from dacon_submit_api import dacon_submit_api \n","\n","result = dacon_submit_api.post_submission_file(\n","'/content/drive/MyDrive/gh/dacon_newstopic/DATA/koelectra_dh3.csv', # 파일경로\n","'9df81cd09375bf4a64d8e0e74e73a5bf83190442474256e9da79999b0cd10c32',  # 개인토큰\n","'235747', # 대회 id\n","'학습기계',  # 팀이름\n","'koelectra_dh3') # 노트"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'isSubmitted': True, 'detail': 'Success'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pyKUEsRaQl03"},"source":[""],"execution_count":null,"outputs":[]}]}
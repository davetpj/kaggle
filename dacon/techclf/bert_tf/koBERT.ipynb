{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"koBERT.ipynb","provenance":[],"machine_shape":"hm","mount_file_id":"1SvuXbgSZHiaKJydnqj-nHO1bRVooS_Fa","authorship_tag":"ABX9TyMEpCKOyd/dYFErV+GXEGCd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmyGiiCrJB4Q","executionInfo":{"status":"ok","timestamp":1628612321036,"user_tz":-540,"elapsed":263,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"3d94fc99-64dc-4963-ea67-2a5913c720fa"},"source":["!nvidia-smi"],"execution_count":68,"outputs":[{"output_type":"stream","text":["Tue Aug 10 16:18:40 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   48C    P0    35W / 250W |  15847MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQViVrBXJOIM","executionInfo":{"status":"ok","timestamp":1628612328718,"user_tz":-540,"elapsed":6422,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"93b774f9-b076-454a-c879-e480cabd1624"},"source":["!pip install transformers==3.2\n","!pip install tensorflow-addons"],"execution_count":69,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers==3.2 in /usr/local/lib/python3.7/dist-packages (3.2.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (4.41.1)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (0.1.96)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (3.0.12)\n","Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (0.8.1rc2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (2019.12.20)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (1.19.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (0.0.45)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (21.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2) (2.4.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2) (7.1.2)\n","Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.13.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B8d6UKC3JbVj","executionInfo":{"status":"ok","timestamp":1628612339221,"user_tz":-540,"elapsed":275,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","import json\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\n","from tensorflow.keras.models import clone_model\n","\n","from tqdm import tqdm\n","\n","# from keras import optimizers\n","from transformers import *\n","# from transformers import BertTokenizer, TFBertModel,PreTrainedTokenizerFast, TFBartModel\n","# from kobart_transformers import get_kobart_tokenizer, get_kobart_model\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.sequence import pad_sequences #tensorflow 전처리 모듈1\n","from tensorflow.keras.preprocessing.text import Tokenizer #tensorflow 전처리 모듈2\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","%matplotlib inline "],"execution_count":70,"outputs":[]},{"cell_type":"code","metadata":{"id":"04kqfNQ2Jgzk","executionInfo":{"status":"ok","timestamp":1628612340348,"user_tz":-540,"elapsed":747,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["import logging\n","import os\n","import unicodedata\n","from shutil import copyfile\n"," \n","from transformers import PreTrainedTokenizer\n"," \n"," \n","logger = logging.getLogger(__name__)\n"," \n","VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n","                     \"vocab_txt\": \"vocab.txt\"}\n"," \n","PRETRAINED_VOCAB_FILES_MAP = {\n","    \"vocab_file\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n","    },\n","    \"vocab_txt\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n","    }\n","}\n"," \n","PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n","    \"monologg/kobert\": 512,\n","    \"monologg/kobert-lm\": 512,\n","    \"monologg/distilkobert\": 512\n","}\n"," \n","PRETRAINED_INIT_CONFIGURATION = {\n","    \"monologg/kobert\": {\"do_lower_case\": False},\n","    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n","    \"monologg/distilkobert\": {\"do_lower_case\": False}\n","}\n"," \n","SPIECE_UNDERLINE = u'▁'\n"," \n"," \n","class KoBertTokenizer(PreTrainedTokenizer):\n","    \"\"\"\n","        SentencePiece based tokenizer. Peculiarities:\n","            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n","    \"\"\"\n","    vocab_files_names = VOCAB_FILES_NAMES\n","    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n","    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n","    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n"," \n","    def __init__(\n","            self,\n","            vocab_file,\n","            vocab_txt,\n","            do_lower_case=False,\n","            remove_space=True,\n","            keep_accents=False,\n","            unk_token=\"[UNK]\",\n","            sep_token=\"[SEP]\",\n","            pad_token=\"[PAD]\",\n","            cls_token=\"[CLS]\",\n","            mask_token=\"[MASK]\",\n","            **kwargs):\n","        super().__init__(\n","            unk_token=unk_token,\n","            sep_token=sep_token,\n","            pad_token=pad_token,\n","            cls_token=cls_token,\n","            mask_token=mask_token,\n","            **kwargs\n","        )\n"," \n","        # Build vocab\n","        self.token2idx = dict()\n","        self.idx2token = []\n","        with open(vocab_txt, 'r', encoding='utf-8') as f:\n","            for idx, token in enumerate(f):\n","                token = token.strip()\n","                self.token2idx[token] = idx\n","                self.idx2token.append(token)\n"," \n","        self.max_len_single_sentence = self.max_len - 2  # take into account special tokens\n","        self.max_len_sentences_pair = self.max_len - 3  # take into account special tokens\n"," \n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n"," \n","        self.do_lower_case = do_lower_case\n","        self.remove_space = remove_space\n","        self.keep_accents = keep_accents\n","        self.vocab_file = vocab_file\n","        self.vocab_txt = vocab_txt\n"," \n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(vocab_file)\n"," \n","    @property\n","    def vocab_size(self):\n","        return len(self.idx2token)\n"," \n","    def __getstate__(self):\n","        state = self.__dict__.copy()\n","        state[\"sp_model\"] = None\n","        return state\n"," \n","    def __setstate__(self, d):\n","        self.__dict__ = d\n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(self.vocab_file)\n"," \n","    def preprocess_text(self, inputs):\n","        if self.remove_space:\n","            outputs = \" \".join(inputs.strip().split())\n","        else:\n","            outputs = inputs\n","        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n"," \n","        if not self.keep_accents:\n","            outputs = unicodedata.normalize('NFKD', outputs)\n","            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n","        if self.do_lower_case:\n","            outputs = outputs.lower()\n"," \n","        return outputs\n"," \n","    def _tokenize(self, text, return_unicode=True, sample=False):\n","        \"\"\" Tokenize a string. \"\"\"\n","        text = self.preprocess_text(text)\n"," \n","        if not sample:\n","            pieces = self.sp_model.EncodeAsPieces(text)\n","        else:\n","            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n","        new_pieces = []\n","        for piece in pieces:\n","            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n","                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n","                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n","                    if len(cur_pieces[0]) == 1:\n","                        cur_pieces = cur_pieces[1:]\n","                    else:\n","                        cur_pieces[0] = cur_pieces[0][1:]\n","                cur_pieces.append(piece[-1])\n","                new_pieces.extend(cur_pieces)\n","            else:\n","                new_pieces.append(piece)\n"," \n","        return new_pieces\n"," \n","    def _convert_token_to_id(self, token):\n","        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n","        return self.token2idx.get(token, self.token2idx[self.unk_token])\n"," \n","    def _convert_id_to_token(self, index, return_unicode=True):\n","        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n","        return self.idx2token[index]\n"," \n","    def convert_tokens_to_string(self, tokens):\n","        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n","        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n","        return out_string\n"," \n","    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n","        by concatenating and adding special tokens.\n","        A RoBERTa sequence has the following format:\n","            single sequence: [CLS] X [SEP]\n","            pair of sequences: [CLS] A [SEP] B [SEP]\n","        \"\"\"\n","        if token_ids_1 is None:\n","            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        sep = [self.sep_token_id]\n","        return cls + token_ids_0 + sep + token_ids_1 + sep\n"," \n","    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n","        \"\"\"\n","        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n","        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n","        Args:\n","            token_ids_0: list of ids (must not contain special tokens)\n","            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n","                for sequence pairs\n","            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n","                special tokens for the model\n","        Returns:\n","            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n","        \"\"\"\n"," \n","        if already_has_special_tokens:\n","            if token_ids_1 is not None:\n","                raise ValueError(\n","                    \"You should not supply a second sequence if the provided sequence of \"\n","                    \"ids is already formated with special tokens for the model.\"\n","                )\n","            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n"," \n","        if token_ids_1 is not None:\n","            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n","        return [1] + ([0] * len(token_ids_0)) + [1]\n"," \n","    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n","        A BERT sequence pair mask has the following format:\n","        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n","        | first sequence    | second sequence\n","        if token_ids_1 is None, only returns the first portion of the mask (0's).\n","        \"\"\"\n","        sep = [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        if token_ids_1 is None:\n","            return len(cls + token_ids_0 + sep) * [0]\n","        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n"," \n","    def save_vocabulary(self, save_directory):\n","        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n","            to a directory.\n","        \"\"\"\n","        if not os.path.isdir(save_directory):\n","            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n","            return\n"," \n","        # 1. Save sentencepiece model\n","        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n"," \n","        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n","            copyfile(self.vocab_file, out_vocab_model)\n"," \n","        # 2. Save vocab.txt\n","        index = 0\n","        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n","        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n","            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n","                if index != token_index:\n","                    logger.warning(\n","                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n","                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n","                    )\n","                    index = token_index\n","                writer.write(token + \"\\n\")\n","                index += 1\n"," \n","        return out_vocab_model, out_vocab_txt"],"execution_count":71,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSNaW3uLJ_fw","executionInfo":{"status":"ok","timestamp":1628623009118,"user_tz":-540,"elapsed":526,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["PATH = '/content/drive/MyDrive/gh/dacon/techclf/DATA'\n","train_df = pd.read_csv(PATH + '/drop_train.csv')\n","test_df = pd.read_csv(PATH + '/drop_test.csv')"],"execution_count":127,"outputs":[]},{"cell_type":"code","metadata":{"id":"qrp5Rd5A9sab","executionInfo":{"status":"ok","timestamp":1628623009120,"user_tz":-540,"elapsed":7,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["# down sampling"],"execution_count":128,"outputs":[]},{"cell_type":"code","metadata":{"id":"LAggsu9iHV7O","executionInfo":{"status":"ok","timestamp":1628623011479,"user_tz":-540,"elapsed":246,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["# cnt = 0\n","# for idx, i in enumerate(range(len(train_df))):\n","#     if train_df.label[i] == 0:\n","#         if cnt > 2000:\n","#             train_df.drop([i], inplace = True)\n","#         cnt +=1"],"execution_count":129,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lj4f2po-25NU","executionInfo":{"status":"ok","timestamp":1628623850327,"user_tz":-540,"elapsed":837886,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"2b934979-e77b-4cf8-e5fc-7471a95e8a13"},"source":["for idx, i in tqdm(enumerate(range(len(train_df)))):\n","    if train_df.label[i] == 0:\n","        if idx % 2 != 0:\n","            train_df.drop([i], inplace = True)"],"execution_count":130,"outputs":[{"output_type":"stream","text":["174304it [13:57, 208.02it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"fchsc_S4NIGK","executionInfo":{"status":"ok","timestamp":1628623850328,"user_tz":-540,"elapsed":8,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["train = train_df\n","test = test_df"],"execution_count":131,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"5hwz3gp3Jtuj","executionInfo":{"status":"ok","timestamp":1628623851234,"user_tz":-540,"elapsed":912,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"1dd30043-d44b-4a0f-8726-831995ef82b3"},"source":["fig, axe = plt.subplots(ncols=1)\n","fig.set_size_inches(6, 3)\n","sns.countplot(train['label'])"],"execution_count":132,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f5669304f90>"]},"metadata":{"tags":[]},"execution_count":132},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x216 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hi3qJ8cWJ5Dy","executionInfo":{"status":"ok","timestamp":1628623851235,"user_tz":-540,"elapsed":24,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"e4efb31e-a0f6-43bb-8cdb-35db0b2b367e"},"source":["tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"],"execution_count":133,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1321: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n","Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PFAik-fBKBNv","executionInfo":{"status":"ok","timestamp":1628623851643,"user_tz":-540,"elapsed":10,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["model_name = 'monologg/kobert'\n","SEED_NUM = 977\n","tf.random.set_seed(SEED_NUM)\n","np.random.seed(SEED_NUM)\n","BATCH_SIZE = 128\n","NUM_EPOCHS = 30\n","VALID_SPLIT = 0.2\n","MAX_LEN = 36\n","NUM_CLASS = 46\n","K_SPLIT = 3"],"execution_count":134,"outputs":[]},{"cell_type":"code","metadata":{"id":"0SVdeIfzKMrl","executionInfo":{"status":"ok","timestamp":1628623851643,"user_tz":-540,"elapsed":10,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["def bert_tokenizer(sent, MAX_LEN):\n","\n","    encoded_dict = tokenizer.encode_plus(\n","        \n","        text = sent,\n","        add_special_tokens = True, # True : 토큰 시작점에 [CLS] 토큰과 토큰의 마지막에 [SEP]토큰을 붙임\n","        max_length = MAX_LEN, # MAX_LEN 최대 길이에 따라 문장의 길이를 맞추는 작업을 진행 ; MAX_LEN보다 길면 truncate\n","        pad_to_max_length = True, # True : MAX_LEN의 길이에 미치지 못하는 문장에 padding을 적용 **padding : 길이를 일괄적으로 맞춰주는 것\n","                                                     # 각 데이터의 길이가 다를경우 모델에 적용할 수 없음 그렇기에 padding진행\n","                                         \n","        return_attention_mask = True, # True : BERT에 필요한 입력값 중 attention_mask를 생성\n","        truncation = True \n","        # encoded_plus 과정 중 token_type으로 문장이 1개면 0, 문장이 2개면 0과 1로 구분\n","    )\n","\n","\n","    input_id = encoded_dict['input_ids'] # BERT 입력값 중 하나인 input_ids\n","    attention_mask = encoded_dict['attention_mask'] # attention_mask ; 단순히 padding과 non-padding을 구분\n","    token_type_id = encoded_dict['token_type_ids'] # 두개의 문장 구분용\n","\n","\n","    return input_id, attention_mask, token_type_id # 각각의 BERT 입력값들을 encoded_dict를 한 결과를 return"],"execution_count":135,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ClxenT-MKUBn","executionInfo":{"status":"ok","timestamp":1628623851644,"user_tz":-540,"elapsed":10,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"7b108d9a-4bc1-4a0b-81c9-58524311a2fa"},"source":["print(tokenizer.all_special_tokens) # BERT special tokens\n","print(tokenizer.all_special_ids)  # BERT special tokens의 index"],"execution_count":136,"outputs":[{"output_type":"stream","text":["['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n","[0, 3, 1, 2, 4]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LKMXBY5TKVUz","executionInfo":{"status":"ok","timestamp":1628623878267,"user_tz":-540,"elapsed":26631,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"b08873df-6dc4-43fc-8d49-fe3a7d51e3b2"},"source":["input_ids = []\n","attention_masks = []\n","token_type_ids = []\n","train_data_labels = []\n","\n","# bert_tokenizer를 이용하여 encoding진행\n","for train_sent, train_label in tqdm(zip(train[\"c_text\"], train[\"label\"])): \n","    try:\n","\n","        input_id, attention_mask, token_type_id = bert_tokenizer(train_sent, MAX_LEN)\n","        \n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        train_data_labels.append(train_label)\n","        \n","    except Exception as e:\n","        print(e)\n","        print(train_sent)\n","        pass\n","\n","\n","train_news_input_ids = np.array(input_ids, dtype=int)\n","train_news_attention_masks = np.array(attention_masks, dtype=int)\n","train_news_type_ids = np.array(token_type_ids, dtype=int)\n","\n","# 최종 출력값은 numpy로 변환한 후 tuple 형태로 묶어서 저장\n","train_news_inputs = (train_news_input_ids, train_news_attention_masks, train_news_type_ids)\n","\n","train_data_labels = np.asarray(train_data_labels, dtype=np.int32) # 정답 tokenizing 리스트\n"],"execution_count":137,"outputs":[{"output_type":"stream","text":["0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","102948it [00:25, 4039.74it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2AcjaAZ4KaTk","executionInfo":{"status":"ok","timestamp":1628623878269,"user_tz":-540,"elapsed":22,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"40baee95-9684-4dc5-a469-344aadb80103"},"source":["INPUT_id = train_news_input_ids[30]\n","ATTENTION_mask = train_news_attention_masks[30]\n","TOKEN_TYPE_id = train_news_type_ids[30]\n","\n","print(INPUT_id)\n","print(ATTENTION_mask)\n","print(TOKEN_TYPE_id)\n","print(tokenizer.decode(INPUT_id))"],"execution_count":138,"outputs":[{"output_type":"stream","text":["[   2 1509 7348 7431 2906 3060 6441 5947 7014 2714 5563 1595 7088 3566\n"," 3969 6312 5575    3    1    1    1    1    1    1    1    1    1    1\n","    1    1    1    1    1    1    1    1]\n","[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","[CLS] 농촌진흥청 수출 심비디움 생산기간 단축을 위한 재배기술[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BIzh62yvKb18","executionInfo":{"status":"ok","timestamp":1628623880296,"user_tz":-540,"elapsed":2044,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"29f8bdfa-9c94-4b40-d108-11067d968314"},"source":["class TFBertClassifier(tf.keras.Model):                                                           \n","    def __init__(self, model_name, dir_path, num_class):\n","        super(TFBertClassifier, self).__init__()\n","        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True)                                                                                   \n","        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n","        self.classifier = tf.keras.layers.Dense(\n","            num_class,\n","            kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n","            name=\"classifier\")\n","\n","\n","    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False): \n","        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        pooled_output = outputs[1]\n","        pooled_output = self.dropout(pooled_output, training=training)\n","        logits = self.classifier(pooled_output)\n","\n","        return logits\n","\n","cls_model = TFBertClassifier(\n","    model_name=model_name,\n","    dir_path='bert_ckpt',\n","    num_class=NUM_CLASS)\n","\n"],"execution_count":139,"outputs":[{"output_type":"stream","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6SyDBnc8K9qq","executionInfo":{"status":"ok","timestamp":1628623880296,"user_tz":-540,"elapsed":14,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["optimizer = tfa.optimizers.RectifiedAdam(learning_rate=5.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","cls_model.compile(\n","    optimizer=optimizer,\n","    loss=loss,\n","    metrics=[metric])"],"execution_count":140,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hJE9v4HrLCV-","executionInfo":{"status":"ok","timestamp":1628623880297,"user_tz":-540,"elapsed":14,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"ef04bb9f-e296-4df7-e229-9f1934969a8e"},"source":["es_callback = EarlyStopping(\n","    monitor='val_loss',\n","    mode='min',\n","    min_delta=0.0001,\n","    patience=5,\n","    baseline=0.4)\n","\n","##\n","DATA_OUT_PATH = PATH + '/data_out'\n","##\n","\n","checkpoint_path = DATA_OUT_PATH + '/best_modeling.ckpt'\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create path if exists\n","if os.path.exists(checkpoint_dir):\n","    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","else:\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","\n","cp_callback = ModelCheckpoint(\n","    checkpoint_path, \n","    monitor='val_loss',\n","    verbose=1, \n","    save_best_only=True, \n","    save_weights_only=True\n","    )\n"],"execution_count":141,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/gh/dacon/techclf/DATA/data_out -- Folder already exists \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OG2tJJgGL5e-","executionInfo":{"status":"ok","timestamp":1628625952899,"user_tz":-540,"elapsed":2072611,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"da697831-d3d6-4d5e-df8f-d10679ddf04c"},"source":["history = cls_model.fit(\n","    train_news_inputs,\n","    train_data_labels,\n","    epochs=NUM_EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    validation_split = VALID_SPLIT,\n","    callbacks=[es_callback, cp_callback]\n","    )"],"execution_count":142,"outputs":[{"output_type":"stream","text":["Epoch 1/30\n","644/644 [==============================] - 462s 616ms/step - loss: 1.7832 - accuracy: 0.6154 - val_loss: 0.9754 - val_accuracy: 0.7579\n","\n","Epoch 00001: val_loss improved from inf to 0.97542, saving model to /content/drive/MyDrive/gh/dacon/techclf/DATA/data_out/best_modeling.ckpt\n","Epoch 2/30\n","644/644 [==============================] - 397s 616ms/step - loss: 0.7877 - accuracy: 0.7827 - val_loss: 0.6564 - val_accuracy: 0.8127\n","\n","Epoch 00002: val_loss improved from 0.97542 to 0.65637, saving model to /content/drive/MyDrive/gh/dacon/techclf/DATA/data_out/best_modeling.ckpt\n","Epoch 3/30\n","644/644 [==============================] - 396s 615ms/step - loss: 0.5684 - accuracy: 0.8299 - val_loss: 0.5491 - val_accuracy: 0.8345\n","\n","Epoch 00003: val_loss improved from 0.65637 to 0.54909, saving model to /content/drive/MyDrive/gh/dacon/techclf/DATA/data_out/best_modeling.ckpt\n","Epoch 4/30\n","644/644 [==============================] - 395s 614ms/step - loss: 0.4484 - accuracy: 0.8625 - val_loss: 0.5330 - val_accuracy: 0.8405\n","\n","Epoch 00004: val_loss improved from 0.54909 to 0.53299, saving model to /content/drive/MyDrive/gh/dacon/techclf/DATA/data_out/best_modeling.ckpt\n","Epoch 5/30\n","644/644 [==============================] - 396s 615ms/step - loss: 0.3512 - accuracy: 0.8913 - val_loss: 0.5210 - val_accuracy: 0.8531\n","\n","Epoch 00005: val_loss improved from 0.53299 to 0.52097, saving model to /content/drive/MyDrive/gh/dacon/techclf/DATA/data_out/best_modeling.ckpt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJxsXSWIL7M5","executionInfo":{"status":"ok","timestamp":1628625952904,"user_tz":-540,"elapsed":11,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"f850b252-68b4-46aa-c36d-0344aded4646"},"source":["cls_model.summary()"],"execution_count":143,"outputs":[{"output_type":"stream","text":["Model: \"tf_bert_classifier_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","tf_bert_model_8 (TFBertModel multiple                  92186880  \n","_________________________________________________________________\n","dropout_341 (Dropout)        multiple                  0         \n","_________________________________________________________________\n","classifier (Dense)           multiple                  35374     \n","=================================================================\n","Total params: 92,222,254\n","Trainable params: 92,222,254\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1wD9DTiMBZQ","executionInfo":{"status":"ok","timestamp":1628625966823,"user_tz":-540,"elapsed":13926,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"461262a6-841d-4dba-b30d-1e35fd13d3ba"},"source":["input_ids = []\n","attention_masks = []\n","token_type_ids = []\n","train_data_labels = []\n","\n","# bert_tokenizer를 이용하여 encoding진행\n","for test_sent in test[\"c_text\"]: \n","    try:\n","\n","        input_id, attention_mask, token_type_id = bert_tokenizer(test_sent, MAX_LEN)\n","        \n","        input_ids.append(input_id)\n","        attention_masks.append(attention_mask)\n","        token_type_ids.append(token_type_id)\n","        \n","    except Exception as e:\n","        print(e)\n","        print(test_sent)\n","        pass\n","\n","test_news_input_ids = np.array(input_ids, dtype=int)\n","test_news_attention_masks = np.array(attention_masks, dtype=int)\n","test_news_type_ids = np.array(token_type_ids, dtype=int)\n","\n","test_news_inputs = (test_news_input_ids, test_news_attention_masks, test_news_type_ids)"],"execution_count":144,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vN9P0nzaMKlk","executionInfo":{"status":"ok","timestamp":1628625970572,"user_tz":-540,"elapsed":3768,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"ec101a3f-d142-4a9a-9363-934a0098995f"},"source":["# model.load_weights(checkpoint_filepath)\n","cls_model_1 = TFBertClassifier(\n","    model_name=model_name,\n","    dir_path='bert_ckpt',\n","    num_class=NUM_CLASS\n","    )\n","\n","cls_model_1.load_weights(os.path.join(DATA_OUT_PATH,'best_modeling.ckpt')) "],"execution_count":145,"outputs":[{"output_type":"stream","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f52370c4050>"]},"metadata":{"tags":[]},"execution_count":145}]},{"cell_type":"code","metadata":{"id":"huG3c86kMS8W","executionInfo":{"status":"ok","timestamp":1628626058239,"user_tz":-540,"elapsed":87673,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["predictions = cls_model_1.predict(test_news_inputs)"],"execution_count":146,"outputs":[]},{"cell_type":"code","metadata":{"id":"v0MQ_BgdMTT8","executionInfo":{"status":"ok","timestamp":1628626058248,"user_tz":-540,"elapsed":26,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["submission = pd.read_csv(PATH + '/sample_submission.csv')"],"execution_count":147,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"g6dp0ZFO3PsP","executionInfo":{"status":"ok","timestamp":1628626058257,"user_tz":-540,"elapsed":33,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"ec454b4d-4409-434f-8a18-ab6aba9e82c2"},"source":["submission"],"execution_count":148,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>174304</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>174305</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>174306</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>174307</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>174308</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>43571</th>\n","      <td>217875</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>43572</th>\n","      <td>217876</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>43573</th>\n","      <td>217877</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>43574</th>\n","      <td>217878</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>43575</th>\n","      <td>217879</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>43576 rows × 2 columns</p>\n","</div>"],"text/plain":["        index  label\n","0      174304      0\n","1      174305      0\n","2      174306      0\n","3      174307      0\n","4      174308      0\n","...       ...    ...\n","43571  217875      0\n","43572  217876      0\n","43573  217877      0\n","43574  217878      0\n","43575  217879      0\n","\n","[43576 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":148}]},{"cell_type":"code","metadata":{"id":"5fLYS7bN3nmq","executionInfo":{"status":"ok","timestamp":1628626058258,"user_tz":-540,"elapsed":23,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["pred = np.argmax(predictions, axis = 1)"],"execution_count":149,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"id":"XHVSEx3I3ea0","executionInfo":{"status":"ok","timestamp":1628626058258,"user_tz":-540,"elapsed":22,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}},"outputId":"e547325c-b5d3-46a6-d739-f158df12a6c9"},"source":["submission.label = pred\n","submission.sample(3)"],"execution_count":150,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>21514</th>\n","      <td>195818</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21918</th>\n","      <td>196222</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>43099</th>\n","      <td>217403</td>\n","      <td>37</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        index  label\n","21514  195818      0\n","21918  196222      0\n","43099  217403     37"]},"metadata":{"tags":[]},"execution_count":150}]},{"cell_type":"code","metadata":{"id":"Te1BtVJi3lEY","executionInfo":{"status":"ok","timestamp":1628626058259,"user_tz":-540,"elapsed":22,"user":{"displayName":"­김동후","photoUrl":"","userId":"05428640934514761408"}}},"source":["submission.to_csv(PATH + '/submission/kobert_half2.csv',index = False)"],"execution_count":151,"outputs":[]},{"cell_type":"code","metadata":{"id":"17_KSqWz4COX"},"source":[""],"execution_count":null,"outputs":[]}]}